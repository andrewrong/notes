### librdkafka使用心得

#### 1. librdkafka库

[librdkafka](https://github.com/edenhill/librdkafka)这个库本身效率还是很不错的，后期测试producer的性能完全能达到它在文档中描述的，甚至能高于它的性能测试结果。总体来讲，是一个不错的库；我同事反应说它的consumer阶段有丢数据的问题，我这次主要用到了它的producer的，所以就producer它很不错的。

#### 2. 关于librakafka的producer

使用过程中有几点总是很不明白;

1. 既然它是自动会处理重传的，那我就认为只要我写道kafka client queue中就发送成功; 但是后来思考的过程中，觉得这样好像不能保证是对的;假如kafka所有的broker都挂了的话，那写到队列中的数据肯定不能算是消费成功的；后来在和朋友的讨论之下，觉得应该是这样的：

    * kafka只是保证它那个层次的消息成功送达，但是这并不保证从应用逻辑层面的消息一定会被送达; 如果从业务层面要保证消息成功到达，除非使用同步的方式，使用异步本身就不能保证消息成功送达. 除非业务逻辑层加ack机制，并且设置消息cache，只有当消息真正被kakfa ack了才把消息从cache中去除; 
    * kakfa client底层所谓的发送也是保存在队列中的，在消息还没有被ack的情况下，消息是不会从queue中去除，这也在一定程度上保证消息送达的可靠性；当发送消息失败之后，这个库也会进行重试，重试的次数是可配置的. *一点不确定,当所有的broker都断了以后，queue中的消息会被重试，这个时候消息会不会慢慢的就会丢弃*,在测试的过程中，发现queue中的消息数一直没有消化，我目测会对这种极端情况进行保证.

2. 关于poll的这个函数完全不明白它是用来做什么的？难道是发送完消息以后我还要做什么处理吗？那个时候觉得既然库已经帮我管理了重传,我还要这个poll做什么呢？后来在看一些文档和测试用例的时候发现，poll的作用其实是一个异步反馈机制，当你发送一条消息之后，此库会有一个回馈机制，用来告诉你是否发送成功，如果没有成功是为什么，当然如果你不关心你可以不调用; 库本身提供了很多个回调函数，我主要使用了eventcb、DeliveryReportCb两个回调，这两个回调主要的用作是监听event和监听消息发送成功的事件;

#### 3. 关于librdkafka的总体架构

不是源码分析这个库，只是对大概的情况进行梳理一下；对应于kafka的client的库，我觉得它应该和很多做存储的client很类似，应该说基本的设计思路类似. 为了之后能更好的使用其他类似的产品库，我觉得对它的设计思路做分析还是很有用的:

1. 此类库基本都应该是异步为主;当然可以提供同步接口的;但是基于同步接口太慢了，所以就不讨论了...如果是异步，通过应用方调用的发送其实就是把消息放到队列中去，然后立刻返回,保证应用方高效性..库本身的后台程序肯定会快速消费队列中的消息...

2. 消息是否真正被送达这个也是很关键的，对于那些消息可靠性送达的有要求的业务方，如果不能得到消息是否送到的反馈，他们是不会接受的;而反馈机制可能让业务方知道消息是否成功被发送、如果没有正常被发送是因为什么原因、亦或者其他重要的事件等，而业务方在得到这些事件的情况下就可以有能力去处理一些事情； 就像上面的情况，业务方可以做业务层的消息保障; 而我通过这些回调函数来判断当前有多少消息已经被成功消费到kakfa，通过统计自己的发送消息个数和成功被处理的消息个数来计算出现在有多少的消息堆积在队列中，并且进行流控; 并且监听了所有kafka全挂的情况下，阻塞的停止业务方的消息产生速度; 这些都是让业务方掌握一些控制权并更加好的使用库;

3. 提供相对比较明确的配置信息.默认值最好就是比较合理，能支持高性能的; 


#### 4. 我自己的封装

其实这个库本身就提供了C++的接口，我仅仅只是再次做了封装...提供处理主要是为了自己在下次遇到的时候能有一个依照;
